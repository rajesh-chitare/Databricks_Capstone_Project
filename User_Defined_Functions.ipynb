{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc5b990-3f8b-47e1-b98c-dc2337e5172a",
     "showTitle": true,
     "title": "Importing Libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57e54a87-2fea-4506-9a0a-49bd908a8c3e",
     "showTitle": true,
     "title": "UDF-1: Basic Info"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_dataframe(df):\n",
    "    \"\"\"Analyzes the given DataFrame and prints various statistics.\"\"\"\n",
    "    \n",
    "    # Define the ANSI escape sequence for black bold text\n",
    "    bold_black = \"\\033[1;30m\"\n",
    "    reset = \"\\033[0m\"\n",
    "\n",
    "    # Get the number of rows\n",
    "    row_count = df.count()\n",
    "    print(f\"{bold_black}\\nNumber of rows:{reset} {row_count}\")\n",
    "\n",
    "    # Get the number of columns\n",
    "    column_count = len(df.columns)\n",
    "    print(f\"{bold_black}Number of columns:{reset} {column_count}\")\n",
    "\n",
    "    # Get column names\n",
    "    column_names = df.columns\n",
    "    print(f\"{bold_black}\\nColumn names:{reset} {column_names}\")\n",
    "\n",
    "    # Get distinct count in each column\n",
    "    distinct_counts = {col: df.select(col).distinct().count() for col in df.columns}\n",
    "    print(f\"{bold_black}\\nDistinct counts for each column:{reset}\")\n",
    "    for col, count in distinct_counts.items():\n",
    "        print(f\"{col}: {count}\")\n",
    "\n",
    "    # Get data types for each column\n",
    "    data_types = {col: df.schema[col].dataType for col in df.columns}\n",
    "    print(f\"{bold_black}\\nData types:{reset}\")\n",
    "    for col, dtype in data_types.items():\n",
    "        print(f\"{col}: {dtype}\")\n",
    "\n",
    "    # Get null values count and percentage for each column\n",
    "    null_info = {col: (df.filter(df[col].isNull()).count(), (df.filter(df[col].isNull()).count() / row_count) * 100) for col in df.columns}\n",
    "    print(f\"{bold_black}\\nNull values count and % Null values:{reset}\")\n",
    "    for col, (null_count, null_percentage) in null_info.items():\n",
    "        print(f\"{col}: {null_count} ({null_percentage:.2f}%)\")\n",
    "\n",
    "    # Get duplicate rows count\n",
    "    print(f\"{bold_black}\\nDuplicate Data Details:{reset}\")\n",
    "    duplicate_count = df.groupBy(df.columns).count().where('count > 1').count()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"Duplicate rows count: {duplicate_count}\")\n",
    "    else:\n",
    "        print(f\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d67ea15c-0a10-45da-8df9-2bfba272a4a0",
     "showTitle": true,
     "title": "UDF-2: Type Casting"
    }
   },
   "outputs": [],
   "source": [
    "def typecast_column(df, column_name, target_type):\n",
    "    type_map = {\n",
    "        'int': IntegerType(),\n",
    "        'long': LongType(),\n",
    "        'float': FloatType(),\n",
    "        'double': DoubleType(),\n",
    "        'short': ShortType(),\n",
    "        'decimal': DecimalType(10, 2),\n",
    "        'str': StringType(),\n",
    "        'bool': BooleanType(),\n",
    "        'date': DateType(),\n",
    "        'timestamp': TimestampType(),\n",
    "        'binary': BinaryType()\n",
    "    }\n",
    "\n",
    "    if target_type not in type_map:\n",
    "        raise ValueError(f\"Unsupported target type: {target_type}\")\n",
    "\n",
    "    return df.withColumn(column_name, col(column_name).cast(type_map[target_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12acd5a2-3a28-4f60-b2c8-bdacf471e85e",
     "showTitle": true,
     "title": "UDF-3: Handling Null Values"
    }
   },
   "outputs": [],
   "source": [
    "def handling_null_values_drop(df):\n",
    "    # Drop the rows with null values\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "540f239b-6faf-4973-b09d-2f09780552c6",
     "showTitle": true,
     "title": "UDF-3: Handling Null Values"
    }
   },
   "outputs": [],
   "source": [
    "def handling_null_values_mean(df):\n",
    "    # Get the mean of each column\n",
    "    mean_values = {col: df.select(mean(col)).collect()[0][0] for col, dtype in df.dtypes if dtype in ['int', 'double']}\n",
    "    \n",
    "    # Fill null values with the mean\n",
    "    df_filled = df.fillna(mean_values)\n",
    "    return df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7b8ad9-8a9f-494b-bfbb-7d6d01229daa",
     "showTitle": true,
     "title": "UDF-4: Removing Unwanted spaces and special char"
    }
   },
   "outputs": [],
   "source": [
    "def strip_empty_space(df, columns):\n",
    "    for column in columns:\n",
    "        df = df.withColumn(column, trim(col(column)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8bc467-46ed-4c3a-87c7-eeee1920bf06",
     "showTitle": true,
     "title": "UDF-5: Removing Unwanted spaces and special char"
    }
   },
   "outputs": [],
   "source": [
    "def remove_special_char(df, columns):\n",
    "    for column in columns:\n",
    "        df = df.withColumn(column, regexp_replace(col(column), '[^a-zA-Z0-9\\s]', ''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b6cd326-3ddd-404c-b8c5-3a082b1b7055",
     "showTitle": true,
     "title": "UDF -6: handling_duplicates"
    }
   },
   "outputs": [],
   "source": [
    "def handling_duplicates(df):\n",
    "    # Drop duplicate rows\n",
    "    return df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6adb187b-3638-40ae-9dc7-6a3e3f8a8c85",
     "showTitle": true,
     "title": "UDF-6: Change to required case"
    }
   },
   "outputs": [],
   "source": [
    "def change_case(df, column_names, operation):\n",
    "    for column_name in column_names:\n",
    "        if operation == 'upper':\n",
    "            df = df.withColumn(column_name, upper(df[column_name]))\n",
    "        elif operation == 'lower':\n",
    "            df = df.withColumn(column_name, lower(df[column_name]))\n",
    "        else:\n",
    "            raise ValueError(\"Operation must be 'upper' or 'lower'\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94438cd-0b22-4240-960e-051bb1eb3aa0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####All functions are imported in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa495bac-f55a-4bc5-8a47-b6d838b68aca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "User_Defined_Functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
